import sysimport os.path#Import the libraries we will need.from IPython.display import displayimport tensorflow as tfimport numpy as npimport matplotlib.pyplot as pltfrom matplotlib.patches import Rectangleimport pandas as pdimport scipy.miscimport scipyimport scipy.ioimport timeimport pickleimport matplotlib.cm as cmimport randomfrom sklearn.metrics import roc_auc_score, precision_recall_curvefrom visualization import visualize_dataset_2d, visualize_dataset_nd, visualize_t_SNE, visualize_z_separate, unknown_dist_hist, visualize_t_SNE_for_trainfrom open_net import OpenNetFlat, OpenNetCNNfrom util.metrics import auc, open_set_classification_metricfrom metrics import auc, open_set_classification_metricimport seaborn as snsdef opt_threshold(true_label, pred_prob):    predictions = np.argmax(pred_prob, axis=1)    binary_truth = np.argmax(true_label, axis=1)    n_labels = len(true_label[0])    result = []    for i in range(n_labels):        mask = (predictions == binary_truth) & (binary_truth == i)      #  print(mask)        threshold = np.min(pred_prob[mask, :].max(axis=1))        result.append(threshold)    return resultdef train_eval(disc_ae, tr_x, tr_y, tr_x_unknown=None, tr_y_unknown=None, center_unknown=None, rot_unknown=None, val_x=None, val_y=None, val_known_mask=None,               ts_x=None, ts_y=None, tr_classes=None, ts_known_mask=None, n_scatter=500, unique_ys=range(7),               train=True, plot_recon=False, grid_shape=(1,3), figsize=(12, 4), save_path=None, save_path_tsne=None, save_path_heatmap=None, save_path_diff=None,               label_text_lookup=None, is_openset=True, visualize=True, acc=None, tr_rot=None, tr_decouple=None, ts_rot=None, rot_label_text_lookup=None,               rot_save_path_tsne=None, pretrain=False, n_cluster=2, print_iir=False):    if train:        train_start = time.time()        disc_ae.fit(tr_x, tr_y, tr_x_unknown, tr_y_unknown,                    val_x[val_known_mask] if val_x is not None else None,                    val_y[val_known_mask, :-1] if val_y is not None else None, rot=tr_rot, decouple=tr_decouple,rot_unknown=rot_unknown)        train_end = time.time()        print("training time: ", int(train_end - train_start))    pred, score = disc_ae.predict_open(ts_x)    predict_prob = disc_ae.predict_prob(ts_x)    if visualize:        z_full = disc_ae.latent(ts_x)        z = disc_ae.latent(tr_x[:n_scatter])        z_unknown = None        if not (tr_x_unknown is None):            z_unknown = disc_ae.latent(tr_x_unknown[:n_scatter//3])        if disc_ae.z_dim > 8:            z = z[:, :-3]            z_full = z_full[:, :-3]            if not (tr_x_unknown is None):                z_unknown = z_unknown[:, :-3]        if z.shape[1] == 2:            visualize_dataset_2d(z[:, 0], z[:, 1], np.argmax(tr_y[:n_scatter], axis=1),                                alpha=0.5, figsize=figsize, unique_ys=unique_ys, save_path=save_path,                                label_text_lookup=label_text_lookup)        elif z.shape[1] == 3:            visualize_dataset_nd(z, np.argmax(tr_y[:n_scatter], axis=1), grid_shape=(1,3), alpha=0.5,                                loc='upper left', bbox_to_anchor=(1.04,1), figsize=figsize,                                unique_ys=unique_ys, save_path=save_path,                                label_text_lookup=label_text_lookup)        else:            # visualize_dataset_nd(z, np.argmax(tr_y[:n_scatter], axis=1), grid_shape=grid_shape, alpha=0.5,            #                     loc='upper left', bbox_to_anchor=(1.04,1), figsize=figsize,            #                     unique_ys=unique_ys, save_path=save_path,            #                     label_text_lookup=label_text_lookup)            total_z = z            total_y = np.argmax(tr_y[:n_scatter], axis=1)            if not pretrain and (center_unknown is not None):              #  total_z = np.concatenate((z, z_unknown), axis=0)               # total_y = np.concatenate((np.argmax(tr_y[:n_scatter], axis=1), np.argmax(tr_y_unknown[:n_scatter], axis=1)))        #        print('tr class ', tr_classes)                visualize_t_SNE_for_train(z, np.argmax(tr_y[:n_scatter], axis=1), z_unknown, np.argmax(tr_y_unknown[:n_scatter//3], axis=1), #open_mnist.test_label()[:1000, 6],                                alpha=0.5, figsize=figsize, unique_ys=unique_ys, save_path=save_path,                                label_text_lookup=label_text_lookup, tr_classes=tr_classes)   #     np.random.seed(0)     #    tr_y_one = np.argmax(ts_y, axis=1)     #    max_n = np.max(tr_y_one) + 1     #    group_n = [[0] for _ in range(int(max_n))]     #    least_n = [0] * int(max_n)     #    print('max_n ', max_n)     #    for id, y in enumerate(tr_y_one):     #        group_n[y].append(id)     #        least_n[y] += 1     #     # #   print(group_n)     #  #  print(least_n)     #    least = min(least_n)     #    idx_list = []     #    for g in group_n:     #        end = min(len(g), 3*least)     #        idx_list.extend(g[1:end])     #  #  print(idx_list)     #    idx = np.array(idx_list)  #      idx =  np.arange(n_scatter)      #  idx = np.arange(len(ts_x))     #   np.random.seed()        idx = np.random.choice(np.arange(len(ts_x)), n_scatter, replace=False)        zs = disc_ae.latent(ts_x[idx])        if disc_ae.z_dim > 8:            zs = zs[:, :-3]        if z.shape[1] == 2:            visualize_dataset_2d(z[:, 0], z[:, 1],                                np.argmax(ts_y[:n_scatter], axis=1), #open_mnist.test_label()[:1000, 6],                                alpha=0.5, figsize=figsize, unique_ys=unique_ys, save_path=save_path,                                label_text_lookup=label_text_lookup)        elif z.shape[1] == 3:            visualize_dataset_nd(z, np.argmax(ts_y[:n_scatter], axis=1), grid_shape=(1,3), alpha=0.5, #grid_shape=(2,3)                                loc='upper left', bbox_to_anchor=(1.04,1), figsize=figsize,          #figsize=(12, 8)                                unique_ys=unique_ys, save_path=save_path,                                label_text_lookup=label_text_lookup)        if not pretrain:            ts_cluster_musk = [False] * len(ts_y)            for i in range(1, n_cluster + 1):                tmp_mask = ts_y[:, -1 - i].astype(bool)                ts_cluster_musk = ts_cluster_musk | tmp_mask            visualize_t_SNE(zs, np.argmax(ts_y[idx], axis=1), ts_known_mask=ts_known_mask[idx], unique_ys=range(7), xlim=(-50, 50), ylim=(-50, 50),                            grid_shape=(1,3), figsize=(12, 4),label_text_lookup=label_text_lookup, save_path=save_path_tsne, tr_classes=tr_classes,                            tr_cluster_mask=ts_cluster_musk[idx])     #   if len(ts_y[0]) != 7:         #   print("unknown distance distribution")          #  unknown_dist_hist(z, np.argmax(ts_y[:n_scatter], axis=1), [1, 5, 7, 8])          #  print("known distance distribution")          #  unknown_dist_hist(z, np.argmax(ts_y[:n_scatter], axis=1), [0, 2, 3, 4, 6, 9])           # unknown_dist_hist(z, np.argmax(ts_y[:n_scatter], axis=1), [0, 2, 3, 4, 6, 9])     #       visualize_dataset_nd(z, np.argmax(ts_y[:n_scatter], axis=1), grid_shape=grid_shape, alpha=0.5,         #                       loc='upper left', bbox_to_anchor=(1.04,1), figsize=figsize,         #                       unique_ys=unique_ys, save_path=save_path,         #                       label_text_lookup=label_text_lookup)    #        print(len(ts_known_mask))     #       visualize_t_SNE(z, np.argmax(ts_y[:n_scatter], axis=1), ts_known_mask[:n_scatter], unique_ys=range(7), xlim=(-80, 80), ylim=(-80, 80),      #               grid_shape=(1,3), figsize=(12, 4),label_text_lookup=label_text_lookup, save_path=save_path_tsne)    #        visualize_t_SNE(z, np.argmax(ts_y[:n_scatter], axis=1), #open_mnist.test_label()[:1000, 6],                  #             alpha=0.5, figsize=figsize, unique_ys=unique_ys, save_path=save_path,                          #     label_text_lookup=label_text_lookup)           # visualize_t_SNE(z, np.argmax(ts_y[:n_scatter], axis=1), ts_known_mask[:n_scatter], unique_ys=range(7),             #       xlim=(-80, 80), ylim=(-80, 80),             #       grid_shape=(1, 3), figsize=(3, 9), label_text_lookup={i: str(c) for i, c in enumerate(range(7))}, save_path=save_path_tsne)    #       visualize_t_SNE(z, pred[:n_scatter], ts_known_mask[:n_scatter], unique_ys=range(7),               #     xlim=(-80, 80), ylim=(-80, 80),               #     grid_shape=(1, 3), figsize=(3, 9), label_text_lookup=label_text_lookup, save_path=save_path_tsne)    #        visualize_t_SNE(z, np.argmax(ts_y[:n_scatter], axis=1), #open_mnist.test_label()[:1000, 6],    #             alpha=0.5, figsize=figsize, unique_ys=unique_ys, save_path=save_path,    #     label_text_lookup=label_text_lookup)    #    labels =  np.argmax(ts_y[:n_scatter], axis=1)        from collections import defaultdict    #    labelz = defaultdict(list)    #    for l, rep in zip(labels, z):    #        labelz[l].append(list(rep))    #    meanallt = []     #   labelall = []     #   for k in labelz:   #        labelall.append(k)       #     meanallt.append(np.mean(labelz[k], axis=0))       # meanall = np.array(meanallt)     #   print("meanall")     #   print(meanall)        known_mask = ts_known_mask[:n_scatter]        unknown_mask = np.logical_not(known_mask)        unknown_mean = np.mean(z[unknown_mask], axis=0, keepdims=True)     #   print("Z shape...")      #  print(len(z[unknown_mask]))        unknown_mean = np.mean(z[unknown_mask], axis=0, keepdims=True)        ss = {'Training':{}, 'Test':{}}        ss['Training']['avg_c_separation'], ss['Training']['min_c_separation'], _ = class_separation(disc_ae.c_means, disc_ae.c_means)        z = disc_ae.latent(tr_x)        if disc_ae.z_dim > 8:            z = z[:,:-3]        ss['Training']['avg_c_spread'], ss['Training']['max_c_spread'], _ = class_spread(disc_ae.c_means, z, tr_y)        if is_openset and tr_classes and print_iir:        #    ss['Test']['avg_c_separation'], ss['Test']['min_c_separation'], _ = class_separation(disc_ae.c_means)          #  z = disc_ae.latent(ts_x[ts_known_mask])            z_full = disc_ae.latent(ts_x)            if disc_ae.z_dim > 8:                z_full = z_full[:, :-3]            n_class = len(np.unique(ts_y, axis=0))            print('n_class, ', n_class)            unknown_classes = [x for x in range(n_class) if x not in tr_classes]            class_means = np.zeros((n_class, disc_ae.c_means.shape[1]))            for i in range(n_class):                rows = np.where(np.argmax(ts_y, axis=1) == i)                class_means[i] = z_full[rows].mean(axis=0)            #            print("ts y shape: ", ts_y[:, :-1].shape)            _, _, all_spread = class_spread(class_means, z_full, ts_y)            unknown_spread = all_spread[tr_classes[-1*n_cluster:]]            known_spread = all_spread[tr_classes[:-1*n_cluster]]            spread = all_spread[tr_classes]            _, _, unknown_sep = class_separation(class_means[tr_classes[-1*n_cluster:]], class_means[tr_classes])            _, _, known_sep = class_separation(class_means[tr_classes[:-1*n_cluster]], class_means[tr_classes])            _, _, sep = class_separation(class_means[tr_classes], class_means[tr_classes])            # unknown_spread = spread[unknown_classes]            # unknown_sep = sep[unknown_classes]            # print('spread ', spread)            # print('sep ', unknown_sep)            # print('class_means ', class_means)            # _, _, spread = class_spread(disc_ae.c_means, z, ts_y[ts_known_mask][:, :-1])            # _, _, sep = class_separation(disc_ae.c_means)            print('unlabeled intra / inter ', np.divide(unknown_spread, unknown_sep).mean(), unknown_spread.max(), unknown_sep.min())            print('labeled intra / inter ', np.divide(known_spread, known_sep).mean(), known_spread.max(), known_sep.min())            print('overall intra / inter ', np.divide(spread, sep).mean(), spread.max(), sep.min())         #   ss['Test']['avg_c_spread'], ss['Test']['max_c_spread'], _ = class_spread(disc_ae.c_means, z,          #                                                                      ts_y[ts_known_mask][:, :-1])         #   test_means = np.zeros(disc_ae.c_means.shape)          #  for i in range(disc_ae.c_means.shape[0]):          #      test_means[i] = z[ts_y[ts_known_mask][:, :-1][:, i].astype(bool)].mean(axis=0)            # print('inter ',  class_separation(disc_ae.c_means)[0])          #  print('intra ',  class_spread(disc_ae.c_means, z, ts_y)[0])      #  means = np.concatenate((disc_ae.c_means, np.copy(unknown_mean)), axis=0)        plt.figure()     #   g = sns.lmplot(x="abs", y="diff", col="cls", data=df,      #             col_wrap=3, height=3)        if save_path_diff:            plt.savefig(save_path_diff, bbox_inches='tight')        #  g = sns.FacetGrid(df, col="cls", col_wrap=3, height=4)      #  g.map(sns.regplot, x="abs", y="diff", color=".3")      #  plt.figure()      #  data_df_2 = data_df_2.sort_values(by=['abs_0'], ascending=False).reset_index(drop=True)     #   dist = np.linalg.norm(data_df_2["0"]-data_df_2["unknown"])       # print("Euclidean distance: " + str(dist))      #  ax1 = sns.lineplot(data=data_df_2[["abs_0","diff"]])      #  ax1.set(ylim=(-4, 4))      #  data_df_2 = pd.DataFrame(np.copy(unknown_mean).T, index, ["unknown"])      #  ax1 = sns.relplot(data=data_df_2, estimator=None,         #   kind="line")     #   ax.add_patch(Rectangle((6, 0), 1, 6, fill=False, edgecolor='green', lw=3))     #   for lab, annot in zip(ax.get_xticklabels(), ax.texts):     #       text = lab.get_text()       #     if text == 'unknown':  # lets highlight row 2                # set the properties of the ticklabel         #       lab.set_weight('bold')          #      lab.set_color('green')                # set the properties of the heatmap annot            #    annot.set_weight('bold')      #  plt.figure()      #  columns_text = ["unknown"]      #  index_text = ["Z0","Z1","Z2","Z3","Z4","Z5"]       # arr_unknown_frame = pd.DataFrame(means.T[:,-1], columns=columns_text, index=index_text)       # fig, ax = plt.subplots(figsize=(1.5, 4), facecolor='w', edgecolor='k')       # cmap = sns.diverging_palette(240, 240, as_cmap=True)       # ax = sns.heatmap(arr_unknown_frame, center=0, vmin=-3, vmax=3, yticklabels=index_text, xticklabels=columns_text, annot=True, cmap=cmap)   # if is_openset:        # print('ts_y, ', np.argmax(tr_y, axis=1))        # print('prob, ', disc_ae.predict_prob(tr_x))        # print('decision, ', disc_ae.decision_function(tr_x))        # train_auc = roc_auc_score(tr_y, disc_ae.predict_prob(tr_x))        #        # precision, recall, thresholds = precision_recall_curve(y_test, y_pred)        #        # fscore = (2 * precision * recall) / (precision + recall)        #        # index = np.argmax(fscore)        # thresholdOpt = round(thresholds[index], ndigits=4)        # fscoreOpt = round(fscore[index], ndigits=4)        # recallOpt = round(recall[index], ndigits=4)        # precisionOpt = round(precision[index], ndigits=4)        # train_prob = disc_ae.predict_prob(tr_x)        # opt_th = opt_threshold(tr_y, train_prob)        # print('threshold, ', opt_th)        # train_max_prob = train_prob.max(axis=1)        # print('test label, ', ts_y, ' len: ', len(ts_y[0]))        # mask = ts_y[:, 6] != 1        # unknown_m = ts_y[:, 6] == 1        # print('mask, ', mask)        # test_prob = disc_ae.predict_prob(ts_x[mask, :])        # plt.figure()        # test_max_prob = test_prob.max(axis=1)        # unknown_test_prob = disc_ae.predict_prob(ts_x[unknown_m, :])        # unknonw_max = unknown_test_prob.max(axis=1)        # sns.kdeplot(train_max_prob)        # plt.figure()        # sns.kdeplot(test_max_prob)        # plt.figure()        # sns.kdeplot(unknonw_max)        #        # train_df = pd.DataFrame(train_prob, columns=['0', '2', '3', '4', '6', '9'])        # test_df = pd.DataFrame(test_prob, columns=['0', '2', '3', '4', '6', '9'])        # unknown_df = pd.DataFrame(unknown_test_prob, columns=['0', '2', '3', '4', '6', '9'])        # plt.figure()        #        # for column in unknown_df.columns:        #     plt.figure()  # <==================== here!        #     sns.distplot(train_df[column])        #     plt.figure()  # <==================== here!        #     sns.distplot(test_df[column])        #     plt.figure()  # <==================== here!        #     sns.distplot(unknown_df[column])      #  auc_score = auc(ts_y[:, -1], disc_ae.decision_function(ts_x), pos_label=1)      #  print auc_score    if plot_recon:        gen_xs = disc_ae.reconstruct(open_mnist.train_data()[:36])        gen_imgs = merge_img(np.reshape(gen_xs[0:len(gen_xs)],[len(gen_xs), disc_ae.x_dim[0], disc_ae.x_dim[1]]))        plt.imshow(gen_imgs, cmap='gray')        plt.show()    unknown_scores = []    known_scores = []    if is_openset:        acc = open_set_classification_metric(np.argmax(ts_y, axis=1),                                       pred, is_openset=is_openset, acc=acc, label_text_lookup=label_text_lookup, save_path_heatmap=save_path_heatmap)        for label, s in zip(np.argmax(ts_y, axis=1), np.amax(predict_prob, axis=1)):            if s < 0:                print(s)            if label == 8:                unknown_scores.append(s)            else:                known_scores.append(s)    else:        acc = open_set_classification_metric(np.argmax(ts_y, axis=1),                                       disc_ae.predict(ts_x), is_openset=is_openset, acc=acc)    #return acc, auc_score, unknown_scores, known_scores, z_full    return acc, z_full, unknown_scores, known_scores# train_eval(disc_ae_2, open_mnist.train_data(), open_mnist.train_label(),#            open_mnist.validation_data(), open_mnist.validation_label(),#            np.logical_not(open_mnist.validation_label()[:,-1].astype(bool)),#            open_mnist.test_data(), open_mnist.test_label(),#            np.logical_not(open_mnist.test_label()[:,-1].astype(bool)),#            n_scatter=1000, unique_ys=range(7)#           )#def compare_performance(model_factory_dict, n_runs,#                        tr_x, tr_y,#                        val_x, val_y, val_known_mask,#                        ts_x, ts_y, ts_known_mask, show_result=True):#    auc_df_avg = 'auc_df_avg'#    auc_df_std = 'auc_df_std'#    auc_df_all = 'auc_df_all'#    results = {key:{} for key in model_factory_dict.keys()}#    start = time.time()#    for model_name, factory in model_factory_dict.items():#        print model_name,#        auc_array = np.zeros(n_runs)#        for n in range(n_runs):#            model = factory()#            model.fit(tr_x, tr_y,#                      val_x[val_known_mask] if val_x is not None else None,#                      val_y[val_known_mask, :-1] if val_y is not None else None)##            auc_array[n] = auc(ts_y[:, -1], model.decision_function(ts_x), pos_label=1, plot=False)#            print '{0:4}'.format(int(time.time() - start)),##        print ''#        if auc_df_avg not in results[model_name]:#            results[model_name][auc_df_avg] = 0.#        results[model_name][auc_df_avg] = auc_array.mean()##        if auc_df_std not in results[model_name]:#            results[model_name][auc_df_std] = 0.#        results[model_name][auc_df_std] = auc_array.std()##        results[model_name][auc_df_all] = auc_array##    if show_result:#        display(pd.DataFrame(results))#    return resultsclass OpenDatasetIter:    def __init__(self, dataset_name, dataset_factory_fn, list_tr_classes, random_seeds='auto'):        """        Parameters        ----------        dataset_name : string            Name of the dataset.        list_tr_classes: list of lists            A list known classes.        dataset_factory_fn: callable            A function that takes a list(knwon classes) and random seed and returns open dataset.        random_seeds: None, list of ints, 'auto'            The random seeds to be passed to dataset_factory_fn. If None the None will be passed.            If 'auto' then deterministic seed values ranging from 1 to len(list_tr_classes)+1 are used.            Otherwise, if is a list then len(random_seeds) == len(list_tr_classes)        """        self.i = 0        self.dataset_name = dataset_name        self.dataset_factory_fn = dataset_factory_fn        self.list_tr_classes = list_tr_classes        self.n = len(self.list_tr_classes)        if random_seeds is None:            self.random_seeds = [None] * self.n        elif random_seeds == 'auto':            self.random_seeds = range(1, self.n+1)        else:            # number of random seeds must equal len of list_tr_classes            assert len(random_seeds) == self.n            self.random_seeds = random_seeds    def __iter__(self):        return self    def next(self):        if self.i < self.n:            tr_classes = self.list_tr_classes[self.i]            seed = self.random_seeds[self.i]            self.i += 1            return self.dataset_name, self.dataset_factory_fn(tr_classes, seed)        else:            raise StopIteration()#OpenDatasetIter(#        'MNIST',#        lambda tr_classes, random_seed: OpenWorldSim(#            mnist.train.images, mnist.train.labels,#            val_data=mnist.validation.images, val_label=mnist.validation.labels,#            test_data=mnist.test.images, test_label=mnist.test.labels,#            tr_classes=tr_classes,  seed=random_seed),#        [[0, 2, 3, 4, 6, 9], [7, 0, 9, 5, 3, 1], [9, 2, 3, 4, 0, 1]], random_seeds='auto')def compare_performance(model_factory_dict, n_runs=1,                        tr_x=None, tr_y=None,                        val_x=None, val_y=None, val_known_mask=None,                        ts_x=None, ts_y=None, ts_known_mask=None,                        show_result=True,                        open_dataset_iterator_factory=None):    auc_df_avg = 'auc_df_avg'    auc_df_std = 'auc_df_std'    auc_df_all = 'auc_df_all'    results = {key:{} for key in model_factory_dict.keys()}    start = time.time()    for model_name, factory in model_factory_dict.items():        print model_name,        auc_array = []        def single_dataset_n_runs():            for n in range(n_runs):                model = factory()                model.fit(tr_x, tr_y,                          val_x[val_known_mask] if val_x is not None else None,                          val_y[val_known_mask, :-1] if val_y is not None else None)                auc_array.append(auc(ts_y[:, -1], model.decision_function(ts_x), pos_label=1, plot=False))                print '{0:4}({1:4.2})'.format(int(time.time() - start), auc_array[-1]),            print ''        if open_dataset_iterator_factory:            iterator = open_dataset_iterator_factory()            for _, open_dataset in iterator:                tr_x = open_dataset.train_data()                tr_y = open_dataset.train_label()                val_x = open_dataset.validation_data()                val_y = open_dataset.validation_label()                val_known_mask = np.logical_not(open_dataset.validation_label()[:,-1].astype(bool))                ts_x = open_dataset.test_data()                ts_y = open_dataset.test_label()                ts_known_mask = np.logical_not(open_dataset.test_label()[:,-1].astype(bool))                single_dataset_n_runs()        else:            single_dataset_n_runs()        auc_array = np.array(auc_array)        if auc_df_avg not in results[model_name]:            results[model_name][auc_df_avg] = 0.        results[model_name][auc_df_avg] = auc_array.mean()        if auc_df_std not in results[model_name]:            results[model_name][auc_df_std] = 0.        results[model_name][auc_df_std] = auc_array.std()        results[model_name][auc_df_all] = auc_array    if show_result:        display(pd.DataFrame(results))    return resultsdef ttest(result_dict, key='auc_df_all'):    import scipy.stats    ttest_p_value = {}    for i, key_i in enumerate(result_dict.keys()):        ttest_p_value[key_i] = {}        for j, key_j in enumerate(result_dict.keys()):            _, pvalue = scipy.stats.ttest_ind(                result_dict[key_i][key],                result_dict[key_j][key])            ttest_p_value[key_i][key_j] = pvalue    display(pd.DataFrame(ttest_p_value))    print 'T-Test PValue'def class_spread(class_means, zs, ys, verbose=False): #   np.set_printoptions(threshold=sys.maxsize)    # assert class_means.shape[0] == ys.shape[1]    class_spread = np.zeros(class_means.shape[0])    for i in range(class_means.shape[0]):        dist_mean = np.square(zs[ys[:, i].astype(bool)] - class_means[i]).sum(axis=1)        class_spread[i] = dist_mean.mean()    if verbose:        np.set_printoptions(precision=5)        print 'Per class avg spread', class_spread        print 'Overall avg spread', class_spread.mean()        print 'Overall avg spread', np.max(class_spread)    else:        return class_spread.mean(), np.max(class_spread), class_spreaddef class_separation(class_means, m2, verbose=False):    n_class = class_means.shape[0]    n2 = m2.shape[0]    all_pair_inter_dist = np.zeros((n_class, n2))    for i in range(n_class):        for j in range(n2):            all_pair_inter_dist[i, j] = (np.square(class_means[i] - m2[j])).sum()    if verbose:        np.set_printoptions(precision=5)        print all_pair_inter_dist        print 'average_inter_dist=' ,  all_pair_inter_dist.mean()        print 'min_inter_dist=' ,  np.amin(all_pair_inter_dist[all_pair_inter_dist > 0.])    else:        return all_pair_inter_dist.mean(), np.amin(all_pair_inter_dist[all_pair_inter_dist > 0.]), np.amin(np.where(all_pair_inter_dist==0., 10000., all_pair_inter_dist), axis=1)